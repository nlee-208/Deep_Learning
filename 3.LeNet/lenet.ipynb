{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"lenet.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"1zPG2ofc3LSkBB8ZLs1BDYt4eOZj6ec4K","authorship_tag":"ABX9TyN3g9jtWyCrsTPigC7HFmKR"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"OXmF3cKpowO9"},"source":["import tensorflow as tf\n","import numpy as np\n","\n","class LeNet:\n","    def __init__(self, config):\n","        self._num_classes = config.num_classes # label 개수 (10개-airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck)\n","        self._l2_reg_lambda = config.l2_reg_lambda #weight decay를 위한 lamda 값\n","\n","        self.X = tf.placeholder(tf.float32, [None, 32, 32, 3], name=\"X\") # 가로: 32, 세로:32, 채널: RGB\n","        self.Y = tf.placeholder(tf.float32, [None, self._num_classes], name=\"Y\") # 정답이 들어올 자리, [0 0 0 0 0 0 0 0 0 1] one-hot encoding 형태\n","        self.keep_prob = tf.placeholder(tf.float32, name=\"keep_prob\") # dropout 살릴 확률\n","        ##############################################################################################################\n","        #                         TODO : LeNet5 모델 생성                                                             #\n","        ##############################################################################################################\n","        # (32, 32, 3) image\n","        # filter1 적용 -> (28, 28, 6) * filter1: 5*5, input_channel: 3, output_channel(# of filters): 6\n","        W1 = tf.Variable(tf.random_normal([5, 5, 3, 6], stddev = 0.01))\n","        L1 = tf.nn.conv2d(self.X, W1, strides= [1, 1, 1, 1], padding = 'VALID')\n","        L1 = tf.nn.relu(L1)\n","        L1 = tf.nn.max_pool(L1, ksize = [1,2,2,1], strides = [1, 2, 2, 1], padding = 'VALID')\n","        # hint he initialization: stddev = sqrt(2/n), filter에서 n 값은?\n","        # relu -> (28, 28, 6)\n","        # max_pooling 적용 -> (14, 14, 6)\n","        # (14, 14, 6) feature map\n","\n","        W2 = tf.Variable(tf.random_normal([5, 5, 6, 16], stddev = 0.01))\n","        L2 = tf.nn.conv2d(L1, W2, strides= [1, 1, 1, 1], padding = 'VALID')\n","        L2 = tf.nn.relu(L2)\n","        L2 = tf.nn.max_pool(L2, ksize = [1,2,2,1], strides = [1, 2, 2, 1], padding = 'VALID')\n","        L2_flat = tf.reshape(L2, [-1, 5*5*16])\n","        # filter2 적용 -> (10, 10, 16) * filter1: 5*5, input_channel: 6, output_channel(# of filters): 16\n","        # relu -> (10, 10, 16)\n","        # max_pooling 적용 -> (5, 5, 16)\n","        # (5, 5, 16) feature map\n","        # 평탄화 -> (5 * 5 *16)        \n","\n","        W3 = tf.get_variable('W3', shape = [5*5*16, 120], initializer = tf.random_normal_initializer(stddev = 0.01))\n","        b3 = tf.Variable(tf.random_normal([120]))\n","        L3 = tf.nn.relu(tf.matmul(L2_flat, W3) + b3)\n","        L3 = tf.nn.dropout(L3, keep_prob = self.keep_prob)\n","        # FC1 추가 (5 * 5 * 16, 120) -> (120)\n","\n","        W4 = tf.get_variable('W4', shape = [120, 84])\n","        b4 = tf.Variable(tf.random_normal([84]))\n","        L4 = tf.nn.relu(tf.matmul(L3, W4) + b4)\n","        L4 = tf.nn.dropout(L4, keep_prob = self.keep_prob)\n","\n","        W5 = tf.get_variable('W5', shape = [84, 10], initializer = tf.random_normal_initializer(stddev = 0.01))\n","        b5 = tf.Variable(tf.random_normal([10]))\n","        # (120) features\n","        # FC2 추가 (120, 84) -> (84)\n","        # (84) features\n","        # Softmax layer 추가 (84) -> (10)\n","        hypothesis = tf.nn.xw_plus_b(L4, W5, b5, name=\"hypothesis\") #hypothesis를 softmax를 통해 확률값으로 변형, Y와 비교해 cross_entropy error 계산\n","\n","\n","        with tf.variable_scope('logit'):\n","            self.predictions = tf.argmax(hypothesis, 1, name=\"predictions\")\n","\n","        with tf.variable_scope('loss'):\n","            costs = []\n","            for var in tf.trainable_variables():\n","                costs.append(tf.nn.l2_loss(var)) # 모든 가중치들의 l2_loss 누적\n","            l2_loss = tf.add_n(costs)\n","            xent = tf.nn.softmax_cross_entropy_with_logits(logits=hypothesis, labels=self.Y)\n","            self.loss = tf.reduce_mean(xent, name='xent') + self._l2_reg_lambda * l2_loss\n","\n","        with tf.name_scope(\"accuracy\"):\n","            correct_predictions = tf.equal(self.predictions, tf.argmax(self.Y, 1))\n","            self.accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"), name=\"accuracy\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zg7rcxXL-qVl"},"source":["# New Section"]}]}