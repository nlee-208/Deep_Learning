{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "from gensim.models.word2vec import PathLineSentences\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time:  427.0390975475311\n",
      "354849\n",
      "0.4715180129323617\n"
     ]
    }
   ],
   "source": [
    "#Setting 1\n",
    "start_time = time.time()\n",
    "sentences = PathLineSentences(\"./data/1billion/\")\n",
    "\n",
    "model = FastText(sentences=sentences, size=100, window=5, min_count=10, workers=4, sg=1, hs=0,\n",
    "                  negative=15, ns_exponent=0.75, alpha=0.01, min_alpha=0.0001, iter=5,\n",
    "                 word_ngrams=1, min_n=2, max_n=3)\n",
    "model.save(\"fastText1.model\")\n",
    "training_time = (time.time() - start_time) / 60\n",
    "print('training time: ', training_time)\n",
    "\n",
    "print(len(model.wv.vocab))\n",
    "score, predictions = model.wv.evaluate_word_analogies('./data/questions-words.txt')\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time:  455.77039226690925\n",
      "354849\n",
      "0.529970235040542\n"
     ]
    }
   ],
   "source": [
    "#Setting 2\n",
    "start_time = time.time()\n",
    "sentences = PathLineSentences(\"./data/1billion/\")\n",
    "\n",
    "model = FastText(sentences=sentences, size=100, window=5, min_count=10, workers=4, sg=1, hs=0,\n",
    "                  negative=15, ns_exponent=0.75, alpha=0.01, min_alpha=0.0001, iter=5,\n",
    "                 word_ngrams=1, min_n=3, max_n=6)\n",
    "model.save(\"fastText2.model\")\n",
    "training_time = (time.time() - start_time) / 60\n",
    "print('training time: ', training_time)\n",
    "\n",
    "print(len(model.wv.vocab))\n",
    "score, predictions = model.wv.evaluate_word_analogies('./data/questions-words.txt')\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time:  768.1800182660421\n",
      "354849\n",
      "0.5660987375551678\n"
     ]
    }
   ],
   "source": [
    "#Setting 3\n",
    "start_time = time.time()\n",
    "sentences = PathLineSentences(\"./data/1billion/\")\n",
    "\n",
    "model = FastText(sentences=sentences, size=300, window=5, min_count=10, workers=4, sg=1, hs=0,\n",
    "                  negative=15, ns_exponent=0.75, alpha=0.01, min_alpha=0.0001, iter=5,\n",
    "                 word_ngrams=1, min_n=2, max_n=3)\n",
    "model.save(\"fastText3.model\")\n",
    "training_time = (time.time() - start_time) / 60\n",
    "print('training time: ', training_time)\n",
    "\n",
    "print(len(model.wv.vocab))\n",
    "score, predictions = model.wv.evaluate_word_analogies('./data/questions-words.txt')\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time:  216.98166175285976\n",
      "354849\n",
      "0.33536898285948885\n"
     ]
    }
   ],
   "source": [
    "#Setting 4\n",
    "start_time = time.time()\n",
    "sentences = PathLineSentences(\"./data/1billion/\")\n",
    "\n",
    "model = FastText(sentences=sentences, size=100, window=5, min_count=10, workers=4, sg=0, hs=0,\n",
    "                  negative=15, ns_exponent=0.75, alpha=0.01, min_alpha=0.0001, iter=5,\n",
    "                 word_ngrams=1, min_n=3, max_n=6)\n",
    "model.save(\"fastText4.model\")\n",
    "training_time = (time.time() - start_time) / 60\n",
    "print('training time: ', training_time)\n",
    "\n",
    "print(len(model.wv.vocab))\n",
    "score, predictions = model.wv.evaluate_word_analogies('./data/questions-words.txt')\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 2.24 GiB for an array with shape (600000000,) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-72154dcb6d3f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFastText\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"fastText1.model\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFastText\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"fastText2.model\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFastText\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"fastText3.model\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mmodel4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFastText\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"fastText4.model\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\noah\\anaconda3\\lib\\site-packages\\gensim\\models\\fasttext.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    930\u001b[0m         \"\"\"\n\u001b[0;32m    931\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 932\u001b[1;33m             \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFastText\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    933\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainables\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'vectors_vocab_lockf'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'vectors_vocab'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\noah\\anaconda3\\lib\\site-packages\\gensim\\models\\base_any2vec.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1229\u001b[0m         \"\"\"\n\u001b[1;32m-> 1230\u001b[1;33m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseWordEmbeddingsModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1231\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ns_exponent'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1232\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mns_exponent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.75\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\noah\\anaconda3\\lib\\site-packages\\gensim\\models\\base_any2vec.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(cls, fname_or_handle, **kwargs)\u001b[0m\n\u001b[0;32m    600\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m         \"\"\"\n\u001b[1;32m--> 602\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseAny2VecModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname_or_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    603\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    604\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname_or_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\noah\\anaconda3\\lib\\site-packages\\gensim\\utils.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(cls, fname, mmap)\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m         \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munpickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 436\u001b[1;33m         \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_load_specials\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmmap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompress\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    437\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"loaded %s\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\noah\\anaconda3\\lib\\site-packages\\gensim\\utils.py\u001b[0m in \u001b[0;36m_load_specials\u001b[1;34m(self, fname, mmap, compress, subname)\u001b[0m\n\u001b[0;32m    465\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"loading %s recursively from %s.* with mmap=%s\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrib\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmmap\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    466\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mignore_deprecation_warning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 467\u001b[1;33m                 \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrib\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_load_specials\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmmap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompress\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    468\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    469\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mattrib\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__numpys'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\noah\\anaconda3\\lib\\site-packages\\gensim\\utils.py\u001b[0m in \u001b[0;36m_load_specials\u001b[1;34m(self, fname, mmap, compress, subname)\u001b[0m\n\u001b[0;32m    476\u001b[0m                 \u001b[0mval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrib\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 478\u001b[1;33m                 \u001b[0mval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrib\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmmap_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmmap\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    479\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    480\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mignore_deprecation_warning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\noah\\anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[0;32m    451\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    452\u001b[0m                 return format.read_array(fid, allow_pickle=allow_pickle,\n\u001b[1;32m--> 453\u001b[1;33m                                          pickle_kwargs=pickle_kwargs)\n\u001b[0m\u001b[0;32m    454\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    455\u001b[0m             \u001b[1;31m# Try a pickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\noah\\anaconda3\\lib\\site-packages\\numpy\\lib\\format.py\u001b[0m in \u001b[0;36mread_array\u001b[1;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[0;32m    753\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misfileobj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    754\u001b[0m             \u001b[1;31m# We can use the fast fromfile() function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 755\u001b[1;33m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    756\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    757\u001b[0m             \u001b[1;31m# This is not a real file. We have to read it the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 2.24 GiB for an array with shape (600000000,) and data type float32"
     ]
    }
   ],
   "source": [
    "model1 = FastText.load(\"fastText1.model\")\n",
    "model2 = FastText.load(\"fastText2.model\")\n",
    "model3 = FastText.load(\"fastText3.model\")\n",
    "model4 = FastText.load(\"fastText4.model\")\n",
    "\n",
    "model_agg = [model1, model2, model3, model4]\n",
    "\n",
    "for i in range(len(model_agg)):\n",
    "    score, predictions = model_agg[i].wv.evaluate_word_analogies('./data/questions-words.txt')\n",
    "    print('For Setting:',str(i+1))\n",
    "    print('Score : {:.3f}'.format(score))\n",
    "    print('Top 3 similar to thank______you : ',model_agg[i].wv.most_similar(\"thank______you\", topn=3))\n",
    "    print('Top 3 similar to showmethemoney: ',model_agg[i].wv.most_similar(\"showmethemoney\", topn=3))\n",
    "    print('Length :',len(model_agg[i].wv.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Setting: 1\n",
      "Score : 0.472\n",
      "Top 3 similar to thank______you :  [('thankyou', 0.8553328514099121), ('cervelat', 0.7965496182441711), ('leviathan', 0.7964868545532227)]\n",
      "Top 3 similar to showmethemoney:  [('showmen', 0.864689290523529), ('precollege', 0.81388258934021), ('divertissement', 0.7962667346000671)]\n",
      "Length : 354849\n"
     ]
    }
   ],
   "source": [
    "model1 = FastText.load(\"fastText1.model\")\n",
    "score, predictions = model1.wv.evaluate_word_analogies('./data/questions-words.txt')\n",
    "print('For Setting: 1')\n",
    "print('Score : {:.3f}'.format(score))\n",
    "print('Top 3 similar to thank______you : ',model1.wv.most_similar(\"thank______you\", topn=3))\n",
    "print('Top 3 similar to showmethemoney: ',model1.wv.most_similar(\"showmethemoney\", topn=3))\n",
    "print('Length :',len(model1.wv.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Setting: 2\n",
      "Score : 0.530\n",
      "Top 3 similar to thank______you :  [('thank', 0.8365939855575562), ('thankyou', 0.8306574821472168), ('thanking', 0.7813167572021484)]\n",
      "Top 3 similar to showmethemoney:  [('tastemaker', 0.801048219203949), ('pantechnicon', 0.7985336780548096), ('BigChampagne', 0.7944570183753967)]\n",
      "Length : 354849\n"
     ]
    }
   ],
   "source": [
    "model2 = FastText.load(\"fastText2.model\")\n",
    "score, predictions = model2.wv.evaluate_word_analogies('./data/questions-words.txt')\n",
    "print('For Setting: 2')\n",
    "print('Score : {:.3f}'.format(score))\n",
    "print('Top 3 similar to thank______you : ',model2.wv.most_similar(\"thank______you\", topn=3))\n",
    "print('Top 3 similar to showmethemoney: ',model2.wv.most_similar(\"showmethemoney\", topn=3))\n",
    "print('Length :',len(model2.wv.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Setting: 3\n",
      "Score : 0.566\n",
      "Top 3 similar to thank______you :  [('thankyou', 0.8656684160232544), ('Thankyou', 0.7103564143180847), ('thang', 0.6696293354034424)]\n",
      "Top 3 similar to showmethemoney:  [('showmen', 0.8114475011825562), ('showmance', 0.7214728593826294), ('endowments', 0.7063639163970947)]\n",
      "Length : 354849\n"
     ]
    }
   ],
   "source": [
    "model3 = FastText.load(\"fastText3.model\")\n",
    "score, predictions = model3.wv.evaluate_word_analogies('./data/questions-words.txt')\n",
    "print('For Setting: 3')\n",
    "print('Score : {:.3f}'.format(score))\n",
    "print('Top 3 similar to thank______you : ',model3.wv.most_similar(\"thank______you\", topn=3))\n",
    "print('Top 3 similar to showmethemoney: ',model3.wv.most_similar(\"showmethemoney\", topn=3))\n",
    "print('Length :',len(model3.wv.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Setting: 4\n",
      "Score : 0.335\n",
      "Top 3 similar to thank______you :  [('thankyou', 0.9870349764823914), ('thank-you', 0.9653881192207336), ('thankyouverymuch', 0.8025739192962646)]\n",
      "Top 3 similar to showmethemoney:  [('colorofmoney', 0.889096736907959), ('mega-money', 0.8742175698280334), ('even-money', 0.8544631600379944)]\n",
      "Length : 354849\n"
     ]
    }
   ],
   "source": [
    "model4 = FastText.load(\"fastText4.model\")\n",
    "score, predictions = model4.wv.evaluate_word_analogies('./data/questions-words.txt')\n",
    "print('For Setting: 4')\n",
    "print('Score : {:.3f}'.format(score))\n",
    "print('Top 3 similar to thank______you : ',model4.wv.most_similar(\"thank______you\", topn=3))\n",
    "print('Top 3 similar to showmethemoney: ',model4.wv.most_similar(\"showmethemoney\", topn=3))\n",
    "print('Length :',len(model4.wv.vocab))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
